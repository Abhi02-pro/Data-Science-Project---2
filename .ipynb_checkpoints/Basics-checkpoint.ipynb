{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hacker News Posts Analysis\n",
    "\n",
    ">In this project, we'll work with a data set of submissions to popular technology site Hacker News.\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/dq-content/354/hacker_news.jpg\" />\n",
    "\n",
    "- Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "- You can find the [data](https://www.kaggle.com/hacker-news/hacker-news-posts) set here, but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "    - **id** : The unique identifier from Hacker News for the post\n",
    "    - **title** : The title of the post\n",
    "    - **url** : The URL that the posts links to, if it the post has a URL\n",
    "    - **num_points** : The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "    - **num_comments** : The number of comments that were made on the post\n",
    "    - **author** : The username of the person who submitted the post\n",
    "    - **created_at** : The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the libraries we need and reading the data set into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'] \n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'] \n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'] \n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "\n",
    "hn = list(read_file)  # storing the data in the file\n",
    "                      # in hn as list of list\n",
    "\n",
    "for row in hn[:5]:    # displaying first five rows\n",
    "    print(row, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first list in the inner lists contains the column headers, and the lists after contain the data for one row. In order to analyze our data, we need to first remove the row containing the column headers. Let's remove that first row next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      " ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      " ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      " ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      " ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      " ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]    # storing the first row in header\n",
    "hn =  hn[1:]       # removing header row from hn\n",
    "\n",
    "print(headers)\n",
    "\n",
    "for row in hn[:5]:\n",
    "    print(\"\\n\", row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed the headers from hn, we're ready to filter our data.\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either **Ask HN** or **Show HN**. \n",
    "- Users submit **Ask HN** posts to ask the Hacker News community a specific question.\n",
    "- Likewise, users submit **Show HN** posts to show the Hacker News community a project, product, or just generally something interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_post =  20100 \n",
      "\n",
      "ask_post =  1744 \n",
      "\n",
      "show_post =  1162 \n",
      "\n",
      "other_post =  17194 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = [] \n",
    "other_posts = []\n",
    "\n",
    "# segregating the data as per our requirement\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(\"total_post = \", len(hn), \"\\n\")\n",
    "print(\"ask_post = \", len(ask_posts), \"\\n\")\n",
    "print(\"show_post = \", len(show_posts), \"\\n\")\n",
    "print(\"other_post = \", len(other_posts), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_ask_comments =  14.038417431192661\n",
      "avg_show_comments =  10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "# calculating total comments on ask posts\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "    \n",
    "# calculating average comments on ask posts\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(\"avg_ask_comments = \", avg_ask_comments)\n",
    "\n",
    "# calculating total comments on show posts\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "    \n",
    "# calculating average comments on show posts\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(\"avg_show_comments = \", avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, ask posts receive more comments than show posts. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_by_hour =  {'05': 46, '04': 47, '13': 85, '17': 100, '18': 109, '06': 44, '14': 107, '02': 58, '09': 45, '01': 60, '22': 71, '11': 58, '23': 68, '16': 108, '07': 34, '19': 110, '08': 48, '03': 54, '21': 109, '10': 59, '00': 55, '15': 116, '20': 80, '12': 73} \n",
      "\n",
      "comments_by_hour =  {'05': 464, '04': 337, '13': 1253, '17': 1146, '18': 1439, '06': 397, '14': 1416, '02': 1381, '09': 251, '01': 683, '22': 479, '11': 641, '23': 543, '16': 1814, '07': 267, '19': 1188, '08': 492, '03': 421, '21': 1745, '10': 793, '00': 447, '15': 4477, '20': 1722, '12': 687}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6],int(row[4])])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comments = row[1]\n",
    "    date = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt.datetime.strftime(date, \"%H\")\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "        \n",
    "# number of ask posts created during each hour of the day\n",
    "print(\"counts_by_hour = \",counts_by_hour,\"\\n\")\n",
    "\n",
    "# number of comments ask posts created at each hour received\n",
    "print(\"comments_by_hour = \",comments_by_hour)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05', 10.08695652173913]\n",
      "['04', 7.170212765957447]\n",
      "['13', 14.741176470588234]\n",
      "['17', 11.46]\n",
      "['18', 13.20183486238532]\n",
      "['06', 9.022727272727273]\n",
      "['14', 13.233644859813085]\n",
      "['02', 23.810344827586206]\n",
      "['09', 5.5777777777777775]\n",
      "['01', 11.383333333333333]\n",
      "['22', 6.746478873239437]\n",
      "['11', 11.051724137931034]\n",
      "['23', 7.985294117647059]\n",
      "['16', 16.796296296296298]\n",
      "['07', 7.852941176470588]\n",
      "['19', 10.8]\n",
      "['08', 10.25]\n",
      "['03', 7.796296296296297]\n",
      "['21', 16.009174311926607]\n",
      "['10', 13.440677966101696]\n",
      "['00', 8.127272727272727]\n",
      "['15', 38.5948275862069]\n",
      "['20', 21.525]\n",
      "['12', 9.41095890410959]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "# calculating the average comments during the specific hour\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "\n",
    "def avg():\n",
    "    for hour in avg_by_hour:\n",
    "        print(hour)\n",
    "        \n",
    "avg()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. We will use sorting to make it easier to determine the results we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.08695652173913, '05'], [7.170212765957447, '04'], [14.741176470588234, '13'], [11.46, '17'], [13.20183486238532, '18'], [9.022727272727273, '06'], [13.233644859813085, '14'], [23.810344827586206, '02'], [5.5777777777777775, '09'], [11.383333333333333, '01'], [6.746478873239437, '22'], [11.051724137931034, '11'], [7.985294117647059, '23'], [16.796296296296298, '16'], [7.852941176470588, '07'], [10.8, '19'], [10.25, '08'], [7.796296296296297, '03'], [16.009174311926607, '21'], [13.440677966101696, '10'], [8.127272727272727, '00'], [38.5948275862069, '15'], [21.525, '20'], [9.41095890410959, '12']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "# swapping the columns to make it easier to sort\n",
    "for hour in avg_by_hour:\n",
    "    swap_avg_by_hour.append([hour[1],hour[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00 : 38.59 average comments per post\n",
      "02:00 : 23.81 average comments per post\n",
      "20:00 : 21.52 average comments per post\n",
      "16:00 : 16.80 average comments per post\n",
      "21:00 : 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for hour in sorted_swap[:5]:\n",
    "    format_hour = dt.datetime.strptime(hour[1],\"%H\")\n",
    "    format_hour = dt.datetime.strftime(format_hour,\"%H:%M\")\n",
    "    print(\"{1} : {0:.2f} average comments per post\".format(hour[0],format_hour))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We can conclude by observing the above results as in the **15th hour** of the day is to be prefered for the post because the post in this hour get more number of comments on an average as compared to the other hours of the day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
